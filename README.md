ğŸ® Temple Run â€“ Hand Gesture Control using OpenCV

Play Temple Run using hand movements captured through your webcam.
This project uses Computer Vision and Hand Gesture Recognition to control the game without a keyboard or mouse.

ğŸ“Œ Project Overview
This system tracks your index finger movement in real time and converts hand gestures into keyboard actions required to play Temple Run.
The project is built using:
OpenCV â€“ video capture & image processing
MediaPipe â€“ hand landmark detection
PyAutoGUI â€“ keyboard control automation

âœ‹ Gesture Controls Mapping
Hand Gesture        Game Action    Keyboard Key
LEFT palm open	     Turn Left	        â†
RIGHT palm open	     Turn Right	        â†’
BOTH hands open        Jump	            â†‘
ONE hand fist	         Slide	          â†“
BOTH hand fist        Neutral           -

ğŸ›  Technologies Used
Python 3.x
OpenCV
MediaPipe
PyAutoGUI
NumPy

ğŸ“¦ Installation
Install all required libraries using pip:
pip install opencv-python mediapipe pyautogui numpy         

â–¶ How to Run the Project
Open Temple Run on your PC or emulator
Make sure the game window is active
Run the Python script:
python templerun.py
Control the game using hand movements in front of your webcam
Press ESC to exit the program

âš™ How It Works
Webcam captures live video
MediaPipe detects hand landmarks
Index finger tip position is tracked
Directional movement is calculated relative to a reference point
Corresponding keyboard key is triggered using PyAutoGUI

ğŸ¯ Performance Tips
Use good lighting for accurate detection
Keep your hand clearly visible inside the camera frame
Maintain a steady reference position before moving
Adjust dead_zone and cooldown values in code if needed

ğŸ“š Learning Outcomes
Computer Vision fundamentals
Real-time hand tracking
Humanâ€“Computer Interaction (HCI)
Game automation using Python
Practical use of OpenCV and MediaPipe

ğŸ§‘â€ğŸ’» Author
Raghini H
Computer Vision | Game Automation | Python
